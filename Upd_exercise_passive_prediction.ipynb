{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Mortgage Delinquency Risk\n",
    "\n",
    "**Note: this is a new exercise, so if you find something weird, please bring it to my attention.**\n",
    "\n",
    "You have been hired by a mortgage servicing firm (a company that buys mortgages and then collects mortgage payments from homeowners) to build a model to answer the question: \n",
    "\n",
    "**Given all available information about a newly issued mortgage, what is the likelihood that the mortgage will enter delinquency (the homeowner will be at least 30 days late on a mortgage payment) during the first two years of the mortgage?**\n",
    "\n",
    "The servicer's hope, obviously, is to differentiate between mortgages to try and purchase (those that will be consistently paid) and mortgages they wish to avoid.\n",
    "\n",
    "For this task, you have been given [REAL data on a sample of all US Standard single family home mortgages purchased or insured by Freddie Mac](https://www.freddiemac.com/research/datasets/sf-loanlevel-dataset) in a single calendar year along with payment data from that and two subsequent years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Gradescope Autograding\n",
    "\n",
    "Please follow [all standard guidance](https://www.practicaldatascience.org/html/autograder_guidelines.html) for submitting this assignment to the Gradescope autograder, including storing your solutions in a dictionary called `results` and ensuring your notebook runs from the start to completion without any errors.\n",
    "\n",
    "For this assignment, please name your file `exercise_passive_prediction.ipynb` before uploading.\n",
    "\n",
    "You can check that you have answers for all questions in your `results` dictionary with this code:\n",
    "\n",
    "```python\n",
    "assert set(results.keys()) == {\n",
    "    \"ex2_merge_type\",\n",
    "    \"ex4_num_mortgages\",\n",
    "    \"ex5_num_obs\",\n",
    "    \"ex7_num_mortgages\",\n",
    "    \"ex7_share_delinquent\",\n",
    "    \"ex10_num_obs\",\n",
    "    \"ex12_roc_auc\",\n",
    "    \"ex14_false_negative_rate\",\n",
    "    \"ex16_num_obs\",\n",
    "    \"ex16_share_delinquent\",\n",
    "    \"ex17_false_negative_rate\",\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "### Submission Limits\n",
    "\n",
    "Please remember that you are **only allowed FOUR submissions to the autograder.** Your last submission (if you submit 4 or fewer times), or your third submission (if you submit more than 4 times) will determine your grade Submissions that error out will **not** count against this total.\n",
    "\n",
    "That's one more than usual in case there are issues with exercise clarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Organization\n",
    "\n",
    "Data for this exercise can be [found here](https://github.com/nickeubank/MIDS_Data/tree/master/mortgages/2004). This folder includes both the data to be used and documentation, though you can find [supplemental documentation here](https://www.freddiemac.com/research/datasets/sf-loanlevel-dataset).\n",
    "\n",
    "The only difference between this data and the original Freddie Mac sampled data is that I've limited the scope of service data to three calendar years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Begin by loading both: \n",
    "\n",
    "- the mortgage origination file (`sample_orig_2004.txt`). This *should* contain information on all mortgages issued in 2004, along with non-time varying features of these mortgages (the initial amount, the credit score of the applicant, etc.), and \n",
    "- the servicing data (`sample_svcg_2004orig_3years.txt`). This contains monthly records of all recorded payments (or non-payments) for all mortgages issued in 2004 during the calendar years of 2004, 2005, and 2006.\n",
    "\n",
    "So the autograder can see the data, be sure to load it directly from a URL (don't download and load from your own system).\n",
    "\n",
    "Load the data AND ensure your data has column names. You will likely need to reference the documentation to figure out how to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5027/2187650068.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "/tmp/ipykernel_5027/2187650068.py:13: DtypeWarning: Columns (4,8,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  servicing_data = pd.read_csv(servicing_url, sep=\"|\", names=servicing_columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   credit_score  1st_payment_date 1st_time_buyer  maturity_date      msa  \\\n",
      "0           701            200403              N         203402  45060.0   \n",
      "1           648            200403              N         202402      NaN   \n",
      "2           653            200403              Y         203402  20740.0   \n",
      "3           747            200403              N         203402  30700.0   \n",
      "4           731            200403              N         201902      NaN   \n",
      "\n",
      "   mi_percent  num_of_units occupancy_status  original_cltv  \\\n",
      "0          25             1                P             90   \n",
      "1           0             1                P             80   \n",
      "2          17             1                P             87   \n",
      "3           0             2                I             70   \n",
      "4           0             1                P             80   \n",
      "\n",
      "   original_dti_ratio  ...  num_borrowers                         seller_name  \\\n",
      "0                  43  ...              2                       Other sellers   \n",
      "1                  46  ...              1                       Other sellers   \n",
      "2                  25  ...              2                       Other sellers   \n",
      "3                  34  ...              1                       Other sellers   \n",
      "4                  40  ...              2  PROVIDENT FUNDING ASSOCIATES, L.P.   \n",
      "\n",
      "                         service_name super_conforming prr_loan_seq_num  \\\n",
      "0                     Other servicers              NaN              NaN   \n",
      "1                     Other servicers              NaN              NaN   \n",
      "2                     Other servicers              NaN              NaN   \n",
      "3                     Other servicers              NaN              NaN   \n",
      "4  PROVIDENT FUNDING ASSOCIATES, L.P.              NaN              NaN   \n",
      "\n",
      "  program_indicator rr_indicator prop_val_method  i/o_indicator  \\\n",
      "0                 9          NaN               9              N   \n",
      "1                 9          NaN               9              N   \n",
      "2                 9          NaN               9              N   \n",
      "3                 9          NaN               9              N   \n",
      "4                 9          NaN               9              N   \n",
      "\n",
      "  mi_cancel_indicator  \n",
      "0                   9  \n",
      "1                   9  \n",
      "2                   9  \n",
      "3                   9  \n",
      "4                   9  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "   loan_seq_num  monthly_rep_per  current_actual_upb current_delinq_status  \\\n",
      "0  F04Q10000027           200402            101000.0                     0   \n",
      "1  F04Q10000027           200403            101000.0                     0   \n",
      "2  F04Q10000027           200404            101000.0                     0   \n",
      "3  F04Q10000027           200405            101000.0                     0   \n",
      "4  F04Q10000027           200406            100000.0                     0   \n",
      "\n",
      "   loan_age  month_to_maturity  defect_settle_date mod_flag  zero_bal_code  \\\n",
      "0         0                360                 NaN      NaN            NaN   \n",
      "1         1                359                 NaN      NaN            NaN   \n",
      "2         2                358                 NaN      NaN            NaN   \n",
      "3         3                357                 NaN      NaN            NaN   \n",
      "4         4                356                 NaN      NaN            NaN   \n",
      "\n",
      "   zero_bal_eff_data  ...  cum_mod_cost  step_mod  payment_deferral  eltv  \\\n",
      "0                NaN  ...           NaN       NaN               NaN   NaN   \n",
      "1                NaN  ...           NaN       NaN               NaN   NaN   \n",
      "2                NaN  ...           NaN       NaN               NaN   NaN   \n",
      "3                NaN  ...           NaN       NaN               NaN   NaN   \n",
      "4                NaN  ...           NaN       NaN               NaN   NaN   \n",
      "\n",
      "   zero_bal_rem_upb  delinq_acuired_int  disaster_delinq  \\\n",
      "0               NaN                 NaN              NaN   \n",
      "1               NaN                 NaN              NaN   \n",
      "2               NaN                 NaN              NaN   \n",
      "3               NaN                 NaN              NaN   \n",
      "4               NaN                 NaN              NaN   \n",
      "\n",
      "   borrower_assist_status  curr_month_mod_cost  int_bearing_upb  \n",
      "0                     NaN                  NaN         101000.0  \n",
      "1                     NaN                  NaN         101000.0  \n",
      "2                     NaN                  NaN         101000.0  \n",
      "3                     NaN                  NaN         101000.0  \n",
      "4                     NaN                  NaN         100000.0  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "origination_url = 'https://media.githubusercontent.com/media/nickeubank/MIDS_Data/master/mortgages/2004/sample_orig_2004.txt'\n",
    "servicing_url = 'https://media.githubusercontent.com/media/nickeubank/MIDS_Data/master/mortgages/2004/sample_svcg_2004orig_3years.txt'\n",
    "\n",
    "origination_columns = [ 'credit_score', '1st_payment_date','1st_time_buyer', 'maturity_date', 'msa', 'mi_percent', 'num_of_units', 'occupancy_status', 'original_cltv', 'original_dti_ratio', 'original_upb', 'original_ltv', 'original_interest_rt', 'channel', 'ppm_flag', 'amortization_type', 'property_state', 'property_type', 'postal_code', 'loan_seq_num', 'loan_purpose', 'original_loan_term', 'num_borrowers', 'seller_name', 'service_name', 'super_conforming', 'prr_loan_seq_num', 'program_indicator', 'rr_indicator', 'prop_val_method', 'i/o_indicator', 'mi_cancel_indicator' ]\n",
    "servicing_columns = [ 'loan_seq_num', 'monthly_rep_per', 'current_actual_upb', 'current_delinq_status', 'loan_age', 'month_to_maturity', 'defect_settle_date', 'mod_flag', 'zero_bal_code','zero_bal_eff_data', 'curr_int_rate', 'curr_non_int_bearing_upb', 'ddlpi', 'mi_recoveries', 'net_sale_proceeds', 'non_mi_recoveries', 'total_exp', 'legal_costs', 'maint_preserve_costs', 'taxes_insurance', 'misc_exp', 'actual_loss_cal', 'cum_mod_cost', 'step_mod', 'payment_deferral', 'eltv', 'zero_bal_rem_upb', 'delinq_acuired_int', 'disaster_delinq', 'borrower_assist_status', 'curr_month_mod_cost', 'int_bearing_upb' ]\n",
    "\n",
    "# Load the mortgage origination data with proper column names\n",
    "origination_data = pd.read_csv(origination_url, sep=\"|\", names=origination_columns)\n",
    "\n",
    "# Load the servicing data with proper column names\n",
    "servicing_data = pd.read_csv(servicing_url, sep=\"|\", names=servicing_columns)\n",
    "\n",
    "# Check the first few rows of the loaded data\n",
    "print(origination_data.head())\n",
    "print(servicing_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "What is the unit of observation in `sample_orig_2004.txt` and in `sample_svcg_2004orig_3years.txt`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER**\n",
    "\n",
    "For the **'sample_orig_2004.txt'** file, which contains origination data, the unit of observation is most likely a unique mortgage loan. Each row in this dataset probably corresponds to a unique loan, with details about the mortgage terms, borrower's credit score, property information, and so on.\n",
    "\n",
    "For the **'sample_svcg_2004orig_3years.txt'** file, which includes servicing data, the unit of observation is usually a monthly record of a mortgage loan's payment status. Each row in this dataset likely represents a single month's payment information for a specific loan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Merge your two datasets. Be sure to use the `validate` keyword argument in `merge`.\n",
    "\n",
    "Assuming that you list the data associated with `sample_orig_2004.txt` first and `sample_svcg_2004orig_3years.txt` second, what keyword are you passing to `validate`? Store your answer as a string (use one of: `\"1:1\"`, `\"m:1\"`, `\"1:m\"`, `\"m:m\"`) in a dictionary called `results` under the key `ex2_merge_type`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   credit_score  1st_payment_date 1st_time_buyer  maturity_date      msa  \\\n",
      "0           701            200403              N         203402  45060.0   \n",
      "1           701            200403              N         203402  45060.0   \n",
      "2           701            200403              N         203402  45060.0   \n",
      "3           701            200403              N         203402  45060.0   \n",
      "4           701            200403              N         203402  45060.0   \n",
      "\n",
      "   mi_percent  num_of_units occupancy_status  original_cltv  \\\n",
      "0          25             1                P             90   \n",
      "1          25             1                P             90   \n",
      "2          25             1                P             90   \n",
      "3          25             1                P             90   \n",
      "4          25             1                P             90   \n",
      "\n",
      "   original_dti_ratio  ...  cum_mod_cost  step_mod  payment_deferral eltv  \\\n",
      "0                  43  ...           NaN       NaN               NaN  NaN   \n",
      "1                  43  ...           NaN       NaN               NaN  NaN   \n",
      "2                  43  ...           NaN       NaN               NaN  NaN   \n",
      "3                  43  ...           NaN       NaN               NaN  NaN   \n",
      "4                  43  ...           NaN       NaN               NaN  NaN   \n",
      "\n",
      "  zero_bal_rem_upb delinq_acuired_int disaster_delinq borrower_assist_status  \\\n",
      "0              NaN                NaN             NaN                    NaN   \n",
      "1              NaN                NaN             NaN                    NaN   \n",
      "2              NaN                NaN             NaN                    NaN   \n",
      "3              NaN                NaN             NaN                    NaN   \n",
      "4              NaN                NaN             NaN                    NaN   \n",
      "\n",
      "   curr_month_mod_cost int_bearing_upb  \n",
      "0                  NaN        101000.0  \n",
      "1                  NaN        101000.0  \n",
      "2                  NaN        101000.0  \n",
      "3                  NaN        101000.0  \n",
      "4                  NaN        100000.0  \n",
      "\n",
      "[5 rows x 63 columns]\n",
      "{'ex2_merge_type': '1:m'}\n"
     ]
    }
   ],
   "source": [
    "merged_data = origination_data.merge(servicing_data, on='loan_seq_num', validate='1:m')\n",
    "\n",
    "results['ex2_merge_type'] = '1:m'\n",
    "\n",
    "print(merged_data.head())\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "Mortgages come in many shapes and flavors, however your servicer is only interested in predicting default for the more standard form of mortgage. Subset your data to only include:\n",
    "\n",
    "- Mortgages taken out for purchase of a property,\n",
    "- With first payments due in the quarter of origination or the first quarter after origination.\n",
    "\n",
    "(In a perfect world we would just limit our analysis to mortgages where the first payment is due the month after origination. Unfortunately we only know the *quarter* of origination, so the only way to subset for relatively vanilla mortgages is to look for mortgages where the first payment was due in the same quarter or the quarter after origination.)\n",
    "\n",
    "Subset for these mortgages. How many unique mortgages remain in the data? \n",
    "\n",
    "Hint: You may need to read the documentation for the `Loan Sequence Number` variable.\n",
    "\n",
    "Store the resulting number of unique mortgages in `results` under the key `ex4_num_mortgages`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique mortgages for purchase with payments due in origination quarter or the next: 14586\n",
      "{'ex2_merge_type': '1:m', 'ex4_num_mortgages': 14586}\n"
     ]
    }
   ],
   "source": [
    "# Filter for purchase loans and explicitly copy to avoid SettingWithCopyWarning\n",
    "purchase_loans = merged_data[merged_data['loan_purpose'] == 'P'].copy()\n",
    "\n",
    "# Directly modify the DataFrame without chained indexing\n",
    "purchase_loans['origination_year'] = 2000 + purchase_loans['loan_seq_num'].str[1:3].astype(int)\n",
    "purchase_loans['origination_quarter'] = purchase_loans['loan_seq_num'].str[4].astype(int)\n",
    "purchase_loans['1st_payment_year'] = (purchase_loans['1st_payment_date'] // 100).astype(int)\n",
    "purchase_loans['1st_payment_month'] = (purchase_loans['1st_payment_date'] % 100).astype(int)\n",
    "purchase_loans['1st_payment_quarter'] = ((purchase_loans['1st_payment_month'] - 1) // 3 + 1).astype(int)\n",
    "\n",
    "# Pre-compute and store conditions to avoid reindexing warnings\n",
    "condition_same_year = (purchase_loans['origination_year'] == purchase_loans['1st_payment_year'])\n",
    "condition_quarter_sequence = (purchase_loans['1st_payment_quarter'] >= purchase_loans['origination_quarter']) & (purchase_loans['1st_payment_quarter'] <= purchase_loans['origination_quarter'] + 1)\n",
    "condition_year_end_turnover = ~((purchase_loans['origination_quarter'] == 4) & (purchase_loans['1st_payment_quarter'] == 1) & (purchase_loans['1st_payment_year'] != purchase_loans['origination_year'] + 1))\n",
    "\n",
    "# Apply conditions to filter valid_loans\n",
    "valid_loans = purchase_loans[condition_same_year & condition_quarter_sequence & condition_year_end_turnover]\n",
    "\n",
    "# Reset index if there have been significant row-wise operations\n",
    "valid_loans.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Count the number of unique mortgages\n",
    "num_unique_mortgages = valid_loans['loan_seq_num'].nunique()\n",
    "\n",
    "# Store the result in a dictionary and print\n",
    "results['ex4_num_mortgages'] = num_unique_mortgages\n",
    "\n",
    "print(f\"Number of unique mortgages for purchase with payments due in origination quarter or the next: {num_unique_mortgages}\")\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "The servicer wants to predict delinquency during the first 24 payment due dates (you may assume payments are due every month starting with the month the first payment is due). Subset the data to these first 24 (possible) payment due dates.\n",
    "\n",
    "Note that not all loans will have 24 records in the servicing file in the first 24 months as a result of data merging issues on behalf of Freddie Mac. As noted in the Freddie Mac documentation:\n",
    "\n",
    "> For a given loan, each monthly reporting period in the monthly performance data file combines data elements from multiple reporting cycles and systems at Freddie Mac. As such, perceived data anomalies may be a result of timing mismatches between default/delinquency reporting cycles and investor reporting cycles. Examples of some commonly occurring anomalies in the data are included throughout this section. In all cases, the best information available at the time the Dataset is generated, subject to operational constraints, is used.\n",
    "\n",
    "So subset for the first two years of (possible) payments, resulting in *up to* 24 observations per mortgage (but potentially less given the data cleanliness issues).\n",
    "\n",
    "After this subsetting, store the number of remaining observations (not mortgages, observation) in `results` under the key `\"ex5_num_obs\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of remaining observations for the first 24 payment due dates: 384291\n",
      "{'ex2_merge_type': '1:m', 'ex4_num_mortgages': 14586, 'ex5_num_obs': 384291}\n"
     ]
    }
   ],
   "source": [
    "# Create a copy to avoid SettingWithCopyWarning when modifying\n",
    "valid_loans = merged_data[merged_data['loan_purpose'] == 'P'].copy()\n",
    "\n",
    "# Compute the year and month directly\n",
    "valid_loans.loc[:, 'monthly_rep_year'] = valid_loans['monthly_rep_per'] // 100\n",
    "valid_loans.loc[:, 'monthly_rep_month'] = valid_loans['monthly_rep_per'] % 100\n",
    "valid_loans.loc[:, '1st_payment_year'] = valid_loans['1st_payment_date'] // 100\n",
    "valid_loans.loc[:, '1st_payment_month'] = valid_loans['1st_payment_date'] % 100\n",
    "\n",
    "# Compute the difference in months between the two dates\n",
    "valid_loans.loc[:, 'month_diff'] = (valid_loans['monthly_rep_year'] - valid_loans['1st_payment_year']) * 12 + \\\n",
    "                                   (valid_loans['monthly_rep_month'] - valid_loans['1st_payment_month'])\n",
    "\n",
    "# Filter the DataFrame to keep only the rows where the difference is between 0 and 23\n",
    "first_24_months = valid_loans[(valid_loans['month_diff'] >= 0) & (valid_loans['month_diff'] < 24)]\n",
    "\n",
    "# Count the number of remaining observations\n",
    "num_remaining_observations = len(first_24_months)\n",
    "\n",
    "# Store the number of remaining observations in the results dictionary\n",
    "results['ex5_num_obs'] = num_remaining_observations\n",
    "\n",
    "# Output the result\n",
    "print(f\"Number of remaining observations for the first 24 payment due dates: {num_remaining_observations}\")\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "For each unique mortgage in your dataset, create an indicator variable that takes on a value of 1 if, at any time during this period, the mortgage has been delinquent.\n",
    "\n",
    "Delinquency status is stored in the variable `CURRENT LOAN DELINQUENCY STATUS`, and is coded as:\n",
    "\n",
    "> CURRENT LOAN DELINQUENCY STATUS – A value corresponding to the number of days the borrower is delinquent, based on the due date of last paid installment (“DDLPI”) reported by servicers to Freddie Mac, and is calculated under the Mortgage Bankers Association (MBA) method.\n",
    "If a loan has been acquired by REO, then the Current Loan Delinquency Status will reflect the value corresponding to that status (instead of the value corresponding to the number of days the borrower is delinquent).\n",
    ">\n",
    "> 0 = Current, or less than 30 days delinquent\n",
    "> \n",
    "> 1 = 30-59 days delinquent\n",
    "> \n",
    "> 2=60–89days delinquent\n",
    "> \n",
    "> 3=90–119days delinquent\n",
    "> \n",
    "> And so on...\n",
    "> \n",
    "> RA = REO Acquisition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique mortgages that have been delinquent: 27765\n",
      "{'ex2_merge_type': '1:m', 'ex4_num_mortgages': 14586, 'ex5_num_obs': 384291, 'ex6_num_delinquent': 27765}\n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame to avoid any potential issues with 'first_24_months' being a view or copy\n",
    "cleaned_loans = first_24_months.copy()\n",
    "\n",
    "# Convert 'current_delinq_status' to numeric, errors='coerce' will turn non-numeric into NaN\n",
    "cleaned_loans.loc[:, 'current_delinq_status'] = pd.to_numeric(cleaned_loans['current_delinq_status'], errors='coerce')\n",
    "\n",
    "# Fill NaN values with 0\n",
    "cleaned_loans.loc[:, 'current_delinq_status'] = cleaned_loans['current_delinq_status'].fillna(0)\n",
    "\n",
    "# Create the delinquency indicator\n",
    "cleaned_loans.loc[:, 'delinquency_indicator'] = cleaned_loans.groupby('loan_seq_num')['current_delinq_status'] \\\n",
    "    .transform(lambda x: 1 if x.gt(0).any() else 0)\n",
    "\n",
    "# Get the number of unique mortgages that have been delinquent\n",
    "num_delinquent_mortgages = cleaned_loans['delinquency_indicator'].sum()\n",
    "\n",
    "# Store the number in the results dictionary\n",
    "results['ex6_num_delinquent'] = num_delinquent_mortgages\n",
    "\n",
    "# Output the result\n",
    "print(f\"Number of unique mortgages that have been delinquent: {num_delinquent_mortgages}\")\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7\n",
    "\n",
    "At this point, you should be able to drop all servicing variables reported on a monthly basis and just keep information about the original mortgage issuance (and still keep an indicator for whether the mortgage has ever been delinquent).\n",
    "\n",
    "Store the final number of mortgages in your data under `ex7_num_mortgages` and the share (between 0 and 1) of mortgages that have been delinquent under `ex7_share_delinquent`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final number of mortgages: 17759\n",
      "Share of mortgages that have been delinquent: 0.07066839349062447\n",
      "{'ex2_merge_type': '1:m', 'ex4_num_mortgages': 14586, 'ex5_num_obs': 384291, 'ex6_num_delinquent': 27765, 'ex7_num_mortgages': 17759, 'ex7_share_delinquent': 0.07066839349062447}\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'cleaned_loans' is your current DataFrame after exercise 6\n",
    "\n",
    "# Define the columns to keep: all columns related to the original mortgage issuance and the delinquency indicator\n",
    "origination_columns = [\n",
    "    'credit_score', '1st_payment_date', '1st_time_buyer', 'maturity_date', 'msa', \n",
    "    'mi_percent', 'num_of_units', 'occupancy_status', 'original_cltv', 'original_dti_ratio', \n",
    "    'original_upb', 'original_ltv', 'original_interest_rt', 'channel', 'ppm_flag', \n",
    "    'amortization_type', 'property_state', 'property_type', 'postal_code', 'loan_seq_num', \n",
    "    'loan_purpose', 'original_loan_term', 'num_borrowers', 'seller_name', 'service_name', \n",
    "    'super_conforming', 'prr_loan_seq_num', 'program_indicator', 'rr_indicator', 'prop_val_method', \n",
    "    'i/o_indicator', 'mi_cancel_indicator', 'delinquency_indicator'\n",
    "]\n",
    "\n",
    "# Keep only the columns related to original mortgage issuance and the delinquency indicator\n",
    "final_dataset = cleaned_loans[origination_columns].drop_duplicates()\n",
    "\n",
    "# Store the final number of mortgages in the results dictionary\n",
    "results['ex7_num_mortgages'] = len(final_dataset)\n",
    "\n",
    "# Calculate and store the share of mortgages that have been delinquent\n",
    "results['ex7_share_delinquent'] = final_dataset['delinquency_indicator'].mean()\n",
    "\n",
    "# Output the result\n",
    "print(f\"Final number of mortgages: {results['ex7_num_mortgages']}\")\n",
    "print(f\"Share of mortgages that have been delinquent: {results['ex7_share_delinquent']}\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling Delinquency Risk\n",
    "\n",
    "Your data should now be relatively [tidy](https://vita.had.co.nz/papers/tidy-data.pdf), in the technical sense of the term. And that means it should be relatively straightforward for you to build a model that answers the question \"Given the features of a newly originated mortgage, how likely is the mortgage holder to fall into delinquency within the first two years after origination?\"\n",
    "\n",
    "### Exercise 8\n",
    "\n",
    "First, we need to identify the target for our model useful predictors from the data and do feature engineering.\n",
    "\n",
    "Let's begin with identifying some features that probably *aren't* going to be useful. For example, `\"Metropolitan Statistical Area (MSA) Or Metropolitan Division\"` is probably *not* an appropriate feature to include in this analysis. Can you figure out why? Make sure to show (quantitatively) why not. \n",
    "\n",
    "Hint: should be more than the missing rate.\n",
    "\n",
    "Hint 2: how many observations for a given city do you think you'd need to determine if that city had especially high mortgage delinquency rates?\n",
    "\n",
    "Hint 3: if not all possible values of a variable are present in your training data, what problem might that cause during testing and deployment?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing rate for MSA: 0.2793513148262853\n",
      "Number of observations per MSA:\n",
      "msa\n",
      "16974.0    370\n",
      "26420.0    341\n",
      "38060.0    309\n",
      "33460.0    295\n",
      "35644.0    279\n",
      "          ... \n",
      "48060.0      1\n",
      "14010.0      1\n",
      "38220.0      1\n",
      "44420.0      1\n",
      "29200.0      1\n",
      "Name: count, Length: 409, dtype: int64\n",
      "Number of unique MSAs: 409\n",
      "Delinquency rates by MSA:\n",
      "msa\n",
      "19260.0    1.000000\n",
      "24420.0    1.000000\n",
      "49500.0    1.000000\n",
      "42100.0    1.000000\n",
      "25060.0    0.833333\n",
      "             ...   \n",
      "29340.0    0.000000\n",
      "29420.0    0.000000\n",
      "29740.0    0.000000\n",
      "30020.0    0.000000\n",
      "29700.0    0.000000\n",
      "Name: delinquency_indicator, Length: 409, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'final_dataset' is the DataFrame after exercise 7\n",
    "\n",
    "# Missing Rate for MSA\n",
    "msa_missing_rate = final_dataset['msa'].isnull().mean()\n",
    "print(f\"Missing rate for MSA: {msa_missing_rate}\")\n",
    "\n",
    "# Observations per MSA\n",
    "msa_counts = final_dataset['msa'].value_counts()\n",
    "print(f\"Number of observations per MSA:\\n{msa_counts}\")\n",
    "\n",
    "# Variety of MSAs\n",
    "unique_msas = final_dataset['msa'].nunique()\n",
    "print(f\"Number of unique MSAs: {unique_msas}\")\n",
    "\n",
    "# Association with Delinquency\n",
    "# For simplicity, we could compare average delinquency rates by MSA\n",
    "msa_delinquency_rates = final_dataset.groupby('msa')['delinquency_indicator'].mean().sort_values(ascending=False)\n",
    "print(f\"Delinquency rates by MSA:\\n{msa_delinquency_rates}\")\n",
    "\n",
    "# Decide whether to include MSA based on these analyses\n",
    "# If MSA does not seem useful, it may be excluded from the model features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9\n",
    "\n",
    "For your analysis, include the following variables: \n",
    "\n",
    "```\n",
    "Credit Score\n",
    "First Time Homebuyer Flag\n",
    "Number of Units\n",
    "Mortgage Insurance Percentage (MI %)\n",
    "Occupancy Status\n",
    "Original Debt-to-Income (DTI) Ratio\n",
    "Original UPB\n",
    "Original Loan-to-Value (LTV)\n",
    "Original Interest Rate\n",
    "Channel\n",
    "Prepayment Penalty Mortgage (PPM) Flag\n",
    "Amortization Type (Formerly Product Type)\n",
    "Property State\n",
    "Property Type\n",
    "Original Loan Term\n",
    "Number of Borrowers\n",
    "Interest Only (I/O) Indicator\n",
    "```\n",
    "\n",
    "Be sure to clean these variables. When doing so, please treat missing data as missing (e.g., `np.nan`, not as a distinct category)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['first_time_homebuyer_flag'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 12\u001b[0m\n\u001b[1;32m      4\u001b[0m analysis_columns \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcredit_score\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst_time_homebuyer_flag\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_of_units\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmi_percent\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moccupancy_status\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal_dti_ratio\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal_upb\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal_ltv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal_interest_rt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchannel\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mppm_flag\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamortization_type\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproperty_state\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproperty_type\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal_loan_term\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_borrowers\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mi/o_indicator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelinquency_indicator\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m ]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Keep only the defined columns\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m analysis_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mfinal_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43manalysis_columns\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Clean the data\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# This is a placeholder: actual cleaning will depend on the specifics of your data\u001b[39;00m\n\u001b[1;32m     16\u001b[0m analysis_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcredit_score\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(np\u001b[38;5;241m.\u001b[39mnan, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# for numerical columns\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:4096\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4094\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4095\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4096\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4098\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:6199\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6197\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6199\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6201\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6203\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:6251\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6250\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6251\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['first_time_homebuyer_flag'] not in index\""
     ]
    }
   ],
   "source": [
    "# Assuming 'final_dataset' is your current DataFrame after exercise 7\n",
    "\n",
    "# Define the columns to keep for the analysis\n",
    "analysis_columns = [\n",
    "    'credit_score', 'first_time_homebuyer_flag', 'num_of_units', 'mi_percent', 'occupancy_status',\n",
    "    'original_dti_ratio', 'original_upb', 'original_ltv', 'original_interest_rt', 'channel',\n",
    "    'ppm_flag', 'amortization_type', 'property_state', 'property_type', 'original_loan_term',\n",
    "    'num_borrowers', 'i/o_indicator', 'delinquency_indicator'\n",
    "]\n",
    "\n",
    "# Keep only the defined columns\n",
    "analysis_dataset = final_dataset[analysis_columns]\n",
    "\n",
    "# Clean the data\n",
    "# This is a placeholder: actual cleaning will depend on the specifics of your data\n",
    "analysis_dataset['credit_score'].fillna(np.nan, inplace=True)  # for numerical columns\n",
    "analysis_dataset['first_time_homebuyer_flag'].replace({'N': 0, 'Y': 1}, inplace=True)  # for flag columns\n",
    "\n",
    "# Now, proceed to check and clean the rest of the variables as needed\n",
    "# ...\n",
    "\n",
    "# Once the cleaning is done, your dataset is ready for further analysis and modeling\n",
    "# You might want to check the cleaned dataset before proceeding\n",
    "print(analysis_dataset.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10\n",
    "\n",
    "The next step in our analysis is to convert our categorical variables to one-hot-encodings and use `train_test_split` to split our data.\n",
    "\n",
    "To ensure replicability, **before** you `train_test_split` your data, please sort your data by `Loan Sequence Number`. This will ensure when we split the data with a random seed below, everyone will get the same split and the autograder will function.\n",
    "\n",
    "You may create your one-hot-encodings however you wish, but I'm a fan of the [patsy library's](https://patsy.readthedocs.io/en/latest/overview.html) `dmatrices` function.\n",
    "\n",
    "Hint: You should end up with 8 categorical variables, including some binary flags and `Number_of_Borrowers`, `Number_of_Units` (which you could argue should be continuous, but I think are better treated as categorical).\n",
    "\n",
    "Store the number of observations in your final dataset in `ex10_num_obs`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11\n",
    "\n",
    "Use `train_test_split` from `sklearn.model_selection` to split the data. \n",
    "\n",
    "Before you do, Use `0.2` as the `test_size` and use `random_state=42`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12\n",
    "\n",
    "Now fit a `GradientBoostingClassifier` to the data (from `sklearn.ensemble`). Set `random_state=42`. using `roc_auc_score`, get your ROC AUC score against the test data. Store in `results` under the key `\"ex12_roc_auc\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 13\n",
    "\n",
    "Use the `predict` method to generate a confusion matrix. What problem do you see with the result?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 14\n",
    "\n",
    "To address the problem from Exercise 13, use `.predict_proba()` to set your own threshold for classification. Your stakeholder is mostly concerned with False Negatives (mortgages classified as safe that actually are not), so use a 8% probability threshold to get a good balance of a low False Negative rate with a reasonable amount of mortgages still being considered \"viable.\"\n",
    "\n",
    "What is the False Negative rate at an 8% classification threshold from the model above?\n",
    "\n",
    "Store the result under the key `\"ex14_false_negative_rate\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15\n",
    "\n",
    "Your stakeholder wants to by as many mortgages as it can while maintaining a delinquency rate of purchased mortgages below 5%. Based on your answer above, do you feel like your model can provide that level of performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now To The Future\n",
    "\n",
    "The preceding analysis is precisely the type of analysis you would do if, in late 2006, you'd been asked to evaluate mortgage performance in the last two years for use going forward. So let's see how your model performs now!\n",
    "\n",
    "In this [folder](https://github.com/nickeubank/MIDS_Data/tree/master/mortgages/2007) you will find data on mortgages originated in 2007 along with servicing data from 2007, 2008, and 2009.\n",
    "\n",
    "### Exercise 16\n",
    "\n",
    "Please load this data (again, from a URL to help the autograder) and clean it in the same manner as before. As a sanity check, how many observations do you have in the final dataset (after you've removed observations with missing values to allow you to generate predicted delinquency rates)? \n",
    "\n",
    "Store the final number of observations in `\"ex16_num_obs\"` and the share of those mortgages that are delinquent in `\"ex16_share_delinquent\"`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 17\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Had your stakeholder purchased mortgages using your model, what would the resulting False Negative rate have been? (e.g., compare the predicted values for mortgages using the model trained above with realized outcomes). Store your result under the key `\"ex17_false_negative_rate\"`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 18\n",
    "\n",
    "How did the retrospective performance of your model compare to its actual performance moving forward? Why? Did you stay below the 5% target for False Negatives set by the stakeholder?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dask_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
